//START TAG: flex-node-affinity-intro
//tag::flex-node-affinity-intro[]
= Select a Node for Flex Gateway Deployments on Kubernetes

Flex Gateway is often critical to the security of a cluster, so it is important to host it on a specialized node that meets specific requirements, instead of using the nodes that host other deployments.

To enable the Kubernetes scheduler to select a suitable host node for a Pod that contains Flex Gateway, you can incorporate custom node affinity rules from your Pod specification (Pod spec) into a Helm chart for your Flex Gateway Ingress Controller. For more information about node affinity, see the https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity[Kubernetes documentation^].

[[list_add_labels]]
== List and Create Node Labels

Each node affinity rule in the Pod spec requires the key of a node label and one or more of the labelâ€™s values. You can use existing node labels or create new ones. A node label is defined as a key-value pair.

* To list a cluster's nodes and node labels, run: 
+
[source,kubernetes,subs=attributes+]
----
kubectl get nodes --show-labels
----

* To create a label for a node in your cluster, run:
+
[source,kubernetes,subs=attributes+]
----
kubectl label nodes <node-name> <label-key>=<label-value>
----

For related Kubernetes documentation, see https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes/#add-a-label-to-a-node[Add a Label to a Node^].
//end::flex-node-affinity-intro[]
//END TAG



//New section
//START TAG
//tag::set-node-affinity[]
[[set_node_affinity]]
== Set Node Affinity for a Pod

The Kubernetes scheduler can use node affinity rules to match nodes to Pods. The matching process enables the scheduler to select the node into which a Pod is deployed.

Configure node affinity rules within a Pod spec. A Pod spec is YAML file in which you can specify rules for required, preferred, or both types of matching:

* `requiredDuringSchedulingIgnoredDuringExecution`: The node must match all node affinity rules configured for a Pod when the Kubernetes scheduler applies this type of matching. Otherwise, the deployment fails. 
* `preferredDuringSchedulingIgnoredDuringExecution`: Based on weighted preferences set for a Pod, the Kubernetes scheduler selects the best matching node. The scheduler must select a node, so if no node matches any of the preferences, the scheduler selects a node that does not match exactly. 
//end::set-node-affinity[]
//END TAG

////
//just informational:
//For guidance, see the following configuration options:
//
//* <<strict_match_only>>
//* <<soft_match_only>>
//* <<all_match_types>>
////


//New section
//START TAG
//tag::flex-node-affinity-required-matching-intro[]
[[required_node_matching]]
=== Configure a Required Node Matching Rule for a Pod 

In required node matching, the node must meet all node affinity rules configured for a Pod. Otherwise, the deployment fails. 
//end::flex-node-affinity-required-matching-intro[]
//END TAG

//START TAG
//tag::flex-node-affinity-common-conditions[]
Configure a node affinity rule in the Pod spec file. Each condition to a rule requires a node label as a `key`, an operator, and one or more node label values to accept for a node with that key. For operators, you can use `In`, `NotIn`, `Exists`,  `DoesNotExist`, `Gt`, and `Lt`.
//end::flex-node-affinity-common-conditions[]
//END TAG

//START TAG
//tag::flex-node-affinity-required-matching-yaml[]
[source,yaml,subs=attributes+]
----
affinity:
 nodeAffinity:
   requiredDuringSchedulingIgnoredDuringExecution:
     nodeSelectorTerms:
     - matchExpressions:
       - key: <node-label-key>
         operator: <operator>
         values:
         - <node-label-value>
       # - Add any other node label values. 
    # - Add any other required conditions.
----

You can add as many values and conditions as the node requires.
//end::flex-node-affinity-required-matching-yaml[]
//END TAG
////
// informational:
// After configuring the Pod spec, proceed to <<upgrade_helm_chart>>.
////

//New section
//START TAG
//tag::flex-node-affinity-preferred-matching-intro[]
[[preferred_node_matching]]
=== Configure a Preferred Node Matching Rule for a Pod

In preferred node matching, the Kubernetes scheduler selects a node based on weighted preferences. The scheduler must select a node, so if no node matches any preferences, the scheduler selects a node that does not match. 

//end::flex-node-affinity-preferred-matching-intro[]
//END TAG

////
// just informational: 
// shared content from tag flex-node-affinity-common-conditions
////

//START TAG
//tag::flex-node-affinity-preferred-conditions[]
In addition, provide a `weight` value between `1` and `100` for each `preference` so that the Kubernetes scheduler can determine which rules are more important and select the best matching node. Matching is based on the sum of the weighted preferences that a node meets. The scheduler selects a node with the greatest total weight over other nodes of lesser weight. 
//end::flex-node-affinity-preferred-conditions[]
//END TAG

//START TAG
//tag::flex-node-affinity-preferred-matching-yaml[]
[source,yaml,subs=attributes+]
----
affinity:
 nodeAffinity:
   preferredDuringSchedulingIgnoredDuringExecution:
   - weight: <integer-x>
     preference:
       matchExpressions:
       - key: <node-label-key1>
         operator: <operator>
         values:
         - <node-label-value>
       # - Add any other values.
    - weight: <integer-y>
      preference:
        matchExpressions:
        - key: <node-label-key2>
          operator: <operator>
          values:
          - <node-label-value>
        # - Add any other node label values. 
      # - Add any other preferred conditions.
  # - Any any more preferred rules.
----

You can add any number of preferred values, conditions, and rules. 
//end::flex-node-affinity-preferred-matching-yaml[]
//END TAG
////
// informational:
// After configuring the Pod spec, proceed to <<upgrade_helm_chart>>.
////



//New section
//START TAG
//tag::flex-node-affinity-mixed-matching-intro[]
[[mixed_node_matching]]
=== Configure Required and Preferred Node Matching Rules for a Pod

You can configure both types of node affinity (required and preferred) in the same YAML file. 
//end::flex-node-affinity-mixed-matching-intro[]
//END TAG
////
// just informational:
// The example combines the settings from <<required_node_matching>> and <<preferred_node_matching>>.  
// tag for shared content from tag flex-node-affinity-common-conditions
// tag for shared content from tag flex-node-affinity-preferred-conditions
////

//START TAG
//tag::flex-node-affinity-mixed-matching-yaml[]
[source,yaml,subs=attributes+]
----
affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
      - matchExpressions:
        - key: <node-label-key>
          operator: <operator>
          values:
          - <node-label-value>
        # - Add any other node label values. 
    # - Add any other conditions.
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: <integer-x>
        preference:
          matchExpressions:
          - key: <node-label-key1>
            operator: <operator>
            values:
            - <node-label-value>
          # - Add any other node label values. 
      - weight: <integer-y>
        preference:
          matchExpressions:
          - key: <node-label-key2>
            operator: <operator>
            values:
            - <node-label-value>
          # - Add any other node label values.
       # - Add any other preferred conditions.
    # - Any any other preferred rules.
----
//end::flex-node-affinity-mixed-matching-yaml[]
//END TAG
////
// informational:
// After configuring the Pod spec, proceed to <<upgrade_helm_chart>>.
////



//START TAG
//tag::upgrade-helm-chart[]
[[upgrade_helm_chart]]
== Upgrade the Helm Chart

After adding the node affinity settings to your Pod spec, incorporate the spec file into the Helm chart for your Flex Gateway Ingress Controller so that the Kubernetes scheduler can use the setting. https://helm.sh/docs/intro/install[Helm^] is a tool used to install Flex Gateway, monitoring tools, and applications. A minimum Helm version of 3.0.0 is required. 

Use a Helm command to incorporate the node affinity settings from your Pod spec into the Helm chart. The command to use depends on whether Flex Gateway is installed:

* If you are installing Flex Gateway for the first time, use this command to set all values in the chart:
+
[source,kubernetes,subs=attributes+]
----
helm -n gateway upgrade -i --create-namespace \ 
--wait ingress flex-gateway/flex-gateway \
-f <path-to-yaml-file> \
--set-file registration.content=<path-to-registration>
----
+
Notice that the command passes the YAML file for the Pod spec.

* If Flex Gateway is installed already, use this command to reuse the chart's existing configuration and set the node affinity configuration:
+
[source,kubernetes,subs=attributes+]
----
helm -n gateway upgrade -i --create-namespace \
--wait ingress flex-gateway/flex-gateway \
--reuse-values -f <path-to-yaml-file>
----
+
Notice that the command passes the YAML file for the Pod spec.

For information about the Helm command, see 
https://helm.sh/docs/helm/helm_upgrade[Helm Upgrade^].
//end::upgrade-helm-chart[]
//END TAG